{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fe2386",
   "metadata": {},
   "source": [
    "# Sentiment analysis on streaming Twitter data using Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6a7e6",
   "metadata": {},
   "source": [
    "- [Stream Tweets in real-time](https://developer.twitter.com/en/docs/tutorials/stream-tweets-in-real-time)\n",
    "- [How to analyze the sentiment of your own Tweets](https://developer.twitter.com/en/docs/tutorials/how-to-analyze-the-sentiment-of-your-own-tweets)\n",
    "- [Apache Spark Streaming Tutorial: Identifying Trending Twitter Hashtags](https://www.toptal.com/apache/apache-spark-streaming-twitter)\n",
    "- [Topic Modeling and Sentiment Analysis on Twitter Data Using Spark](https://towardsdatascience.com/topic-modeling-and-sentiment-analysis-on-twitter-data-using-spark-a145bfcc433)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6ea00",
   "metadata": {},
   "source": [
    "### Send tweets from the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae8d5d",
   "metadata": {},
   "source": [
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "import socket\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import requests_oauthlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94349b9f",
   "metadata": {},
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key='3VQqLVDmUzFsbd9jnZ9q1jUH2'\n",
    "consumer_secret='KhDLpqs9QECXzXLzulwIBiFkhLl3IBd8UhbaLMZUaAQwy0WQY2'\n",
    "access_token ='1439283727784423430-CXAd1gXrgBuHQFfwBxtHsU5RRqnrBN'\n",
    "access_secret='g7oBc5orMh72N8bjK7MLwMK75eLRPPt47ux3hfa9l7FlH'\n",
    "\n",
    "# auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "# auth.set_access_token(access_token, access_secret)\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efe3e5",
   "metadata": {},
   "source": [
    "#### API Key\n",
    "Think of the API key as the user name that represents your App when making API requests. It helps us verify who you are.\n",
    "\n",
    "#### API Key Secret\n",
    "Your API Key Secret is like a password and helps verify your API Key. This will be one of the last times you'll see it displayed, so remember to save it in a safe place.\n",
    "\n",
    "#### Bearer Token\n",
    "An Access Token used in authentication that allows you to pull specific data.\n",
    "\n",
    "#### Access Token\n",
    "\n",
    "#### Access Token Secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad2522",
   "metadata": {},
   "source": [
    "#### Create a StreamListener instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsListener(StreamListener):\n",
    "    # tweet object listens for the tweets\n",
    "    def __init__(self, csocket):\n",
    "        self.client_socket = csocket\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        try:  \n",
    "            msg = json.loads( data )\n",
    "            print(\"new message\")\n",
    "            # if tweet is longer than 140 characters\n",
    "            \n",
    "            \n",
    "            if \"extended_tweet\" in msg:\n",
    "                # add at the end of each tweet \"t_end\" \n",
    "                self.client_socket\\\n",
    "                    .send(str(msg['extended_tweet']['full_text']+\"t_end\")\\\n",
    "                    .encode('utf-8'))         \n",
    "                print(msg['extended_tweet']['full_text'])\n",
    "\n",
    "            \n",
    "            else:\n",
    "                # add at the end of each tweet \"t_end\" \n",
    "                self.client_socket\\\n",
    "                    .send(str(msg['text']+\"t_end\")\\\n",
    "                    .encode('utf-8'))\n",
    "                print(msg['text'])\n",
    "            return True\n",
    "        \n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073adf1f",
   "metadata": {},
   "source": [
    "#### Send data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendData(c_socket, keyword):\n",
    "    print('start sending data from Twitter to socket')\n",
    "    \n",
    "    # authentication based on the credentials\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    \n",
    "    # start sending data from the Streaming API \n",
    "    twitter_stream = Stream(auth, TweetsListener(c_socket))\n",
    "    twitter_stream.filter(track = keyword, languages=[\"en\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2decafbb",
   "metadata": {},
   "source": [
    "#### Start Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # server (local machine) creates listening socket\n",
    "    s = socket.socket()\n",
    "    host = ''\n",
    "    port = 5555\n",
    "    try:\n",
    "        s.bind((host, port))\n",
    "    \n",
    "    except socket.error as msg:\n",
    "        print('Bind failed. Error Code : ' + str(msg[0]) + ' Message ' + msg[1])\n",
    "        sys.exit()\n",
    "\n",
    "    print('Socket bind complete')\n",
    "    print('socket is ready')\n",
    "    \n",
    "\n",
    "    \n",
    "    # server (local machine) listens for connections\n",
    "    s.listen(4)\n",
    "    print('socket is listening')\n",
    "    \n",
    "    \n",
    "    # return the socket and the address on the other side of the connection (client side)\n",
    "    c_socket, addr = s.accept()\n",
    "    print(\"Received request from: \" + str(addr))\n",
    "    \n",
    "    \n",
    "    # select here the keyword for the tweet data\n",
    "    sendData(c_socket, keyword = ['The Comeback Trail'])\n",
    "# The Comeback Trail” / “Robert De Niro”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0852f0",
   "metadata": {},
   "source": [
    "### Tweet preprocessing and sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ebc2b",
   "metadata": {},
   "source": [
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291864e",
   "metadata": {},
   "source": [
    "#### Tweet preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(lines):\n",
    "    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n",
    "    words = words.na.replace('', None)\n",
    "    words = words.na.drop()\n",
    "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6d8da",
   "metadata": {},
   "source": [
    "#### Tweet sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e888c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification\n",
    "def polarity_detection(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99047bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_detection(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea173b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classification(words):\n",
    "    \n",
    "    # polarity detection\n",
    "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
    "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
    "    \n",
    "    # subjectivity detection\n",
    "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
    "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da578c76",
   "metadata": {},
   "source": [
    "#### Run the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6329212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # create Spark session\n",
    "    spark = SparkSession.builder.appName(\"TwitterSentimentAnalysis\").getOrCreate()\n",
    "    \n",
    "    # read the tweet data from socket\n",
    "    lines = spark.readStream.format(\"socket\").option(\"host\", \"0.0.0.0\").option(\"port\", 5555).load()\n",
    "    \n",
    "    # Preprocess the data\n",
    "    words = preprocessing(lines)\n",
    "    \n",
    "    # text classification to define polarity and subjectivity\n",
    "    words = text_classification(words)\n",
    "    words = words.repartition(1)\n",
    "    \n",
    "    query = words.writeStream.queryName(\"all_tweets\")\\\n",
    "        .outputMode(\"append\").format(\"parquet\")\\\n",
    "        .option(\"path\", \"./parc\")\\\n",
    "        .option(\"checkpointLocation\", \"./check\")\\\n",
    "        .trigger(processingTime='60 seconds').start()\n",
    "    \n",
    "    query.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
