{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fe2386",
   "metadata": {},
   "source": [
    "# Sentiment analysis on streaming Twitter data using Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6a7e6",
   "metadata": {},
   "source": [
    "- [Stream Tweets in real-time](https://developer.twitter.com/en/docs/tutorials/stream-tweets-in-real-time)\n",
    "- [How to analyze the sentiment of your own Tweets](https://developer.twitter.com/en/docs/tutorials/how-to-analyze-the-sentiment-of-your-own-tweets)\n",
    "- [Apache Spark Streaming Tutorial: Identifying Trending Twitter Hashtags](https://www.toptal.com/apache/apache-spark-streaming-twitter)\n",
    "- [Topic Modeling and Sentiment Analysis on Twitter Data Using Spark](https://towardsdatascience.com/topic-modeling-and-sentiment-analysis-on-twitter-data-using-spark-a145bfcc433)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f6ea00",
   "metadata": {},
   "source": [
    "### Send tweets from the Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ae8d5d",
   "metadata": {},
   "source": [
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c44ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "import socket\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "import requests_oauthlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94349b9f",
   "metadata": {},
   "source": [
    "#### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2f9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Twitter API for each tweet in the Twitter archive and save JSON in a text file\n",
    "# These are hidden to comply with Twitter's API terms and conditions\n",
    "consumer_key='3VQqLVDmUzFsbd9jnZ9q1jUH2'\n",
    "consumer_secret='KhDLpqs9QECXzXLzulwIBiFkhLl3IBd8UhbaLMZUaAQwy0WQY2'\n",
    "access_token ='1439283727784423430-CXAd1gXrgBuHQFfwBxtHsU5RRqnrBN'\n",
    "access_secret='g7oBc5orMh72N8bjK7MLwMK75eLRPPt47ux3hfa9l7FlH'\n",
    "\n",
    "# auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "# auth.set_access_token(access_token, access_secret)\n",
    "# api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efe3e5",
   "metadata": {},
   "source": [
    "#### API Key\n",
    "Think of the API key as the user name that represents your App when making API requests. It helps us verify who you are.\n",
    "- 3VQqLVDmUzFsbd9jnZ9q1jUH2\n",
    "\n",
    "#### API Key Secret\n",
    "Your API Key Secret is like a password and helps verify your API Key. This will be one of the last times you'll see it displayed, so remember to save it in a safe place.\n",
    "- KhDLpqs9QECXzXLzulwIBiFkhLl3IBd8UhbaLMZUaAQwy0WQY2\n",
    "\n",
    "#### Bearer Token\n",
    "An Access Token used in authentication that allows you to pull specific data.\n",
    "- AAAAAAAAAAAAAAAAAAAAADF3TwEAAAAA3oiigSHCMJ4ZgF4p0vVzd9zqKVs%3DcYEiSooAwKGC4qPuc6h4aN9kzM7ujJkePQfSYbsvz7snYp33by\n",
    "\n",
    "#### Access Token\n",
    "- 1439283727784423430-CXAd1gXrgBuHQFfwBxtHsU5RRqnrBN\n",
    "\n",
    "#### Access Token Secret\n",
    "- g7oBc5orMh72N8bjK7MLwMK75eLRPPt47ux3hfa9l7FlH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad2522",
   "metadata": {},
   "source": [
    "#### Create a StreamListener instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4d5eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetsListener(StreamListener):\n",
    "    # tweet object listens for the tweets\n",
    "    def __init__(self, csocket):\n",
    "        self.client_socket = csocket\n",
    "        \n",
    "    def on_data(self, data):\n",
    "        try:  \n",
    "            msg = json.loads( data )\n",
    "            print(\"new message\")\n",
    "            # if tweet is longer than 140 characters\n",
    "            \n",
    "            \n",
    "            if \"extended_tweet\" in msg:\n",
    "                # add at the end of each tweet \"t_end\" \n",
    "                self.client_socket\\\n",
    "                    .send(str(msg['extended_tweet']['full_text']+\"t_end\")\\\n",
    "                    .encode('utf-8'))         \n",
    "                print(msg['extended_tweet']['full_text'])\n",
    "\n",
    "            \n",
    "            else:\n",
    "                # add at the end of each tweet \"t_end\" \n",
    "                self.client_socket\\\n",
    "                    .send(str(msg['text']+\"t_end\")\\\n",
    "                    .encode('utf-8'))\n",
    "                print(msg['text'])\n",
    "            return True\n",
    "        \n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    "    \n",
    "    def on_error(self, status):\n",
    "        print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073adf1f",
   "metadata": {},
   "source": [
    "#### Send data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050a5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sendData(c_socket, keyword):\n",
    "    print('start sending data from Twitter to socket')\n",
    "    \n",
    "    # authentication based on the credentials\n",
    "    auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_secret)\n",
    "    \n",
    "    # start sending data from the Streaming API \n",
    "    twitter_stream = Stream(auth, TweetsListener(c_socket))\n",
    "    twitter_stream.filter(track = keyword, languages=[\"en\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2decafbb",
   "metadata": {},
   "source": [
    "#### Start Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7e3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # server (local machine) creates listening socket\n",
    "    s = socket.socket()\n",
    "    host = ''\n",
    "    port = 5555\n",
    "    try:\n",
    "        s.bind((host, port))\n",
    "    \n",
    "    except socket.error as msg:\n",
    "        print('Bind failed. Error Code : ' + str(msg[0]) + ' Message ' + msg[1])\n",
    "        sys.exit()\n",
    "\n",
    "    print('Socket bind complete')\n",
    "    print('socket is ready')\n",
    "    \n",
    "\n",
    "    \n",
    "    # server (local machine) listens for connections\n",
    "    s.listen(4)\n",
    "    print('socket is listening')\n",
    "    \n",
    "    \n",
    "    # return the socket and the address on the other side of the connection (client side)\n",
    "    c_socket, addr = s.accept()\n",
    "    print(\"Received request from: \" + str(addr))\n",
    "    \n",
    "    \n",
    "    # select here the keyword for the tweet data\n",
    "    sendData(c_socket, keyword = ['The Comeback Trail'])\n",
    "# The Comeback Trail” / “Robert De Niro”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0852f0",
   "metadata": {},
   "source": [
    "### Tweet preprocessing and sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535ebc2b",
   "metadata": {},
   "source": [
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "811c6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291864e",
   "metadata": {},
   "source": [
    "#### Tweet preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9bb3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(lines):\n",
    "    words = lines.select(explode(split(lines.value, \"t_end\")).alias(\"word\"))\n",
    "    words = words.na.replace('', None)\n",
    "    words = words.na.drop()\n",
    "    words = words.withColumn('word', F.regexp_replace('word', r'http\\S+', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', '@\\w+', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', '#', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', 'RT', ''))\n",
    "    words = words.withColumn('word', F.regexp_replace('word', ':', ''))\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6d8da",
   "metadata": {},
   "source": [
    "#### Tweet sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e888c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text classification\n",
    "def polarity_detection(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99047bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subjectivity_detection(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea173b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classification(words):\n",
    "    \n",
    "    # polarity detection\n",
    "    polarity_detection_udf = udf(polarity_detection, StringType())\n",
    "    words = words.withColumn(\"polarity\", polarity_detection_udf(\"word\"))\n",
    "    \n",
    "    # subjectivity detection\n",
    "    subjectivity_detection_udf = udf(subjectivity_detection, StringType())\n",
    "    words = words.withColumn(\"subjectivity\", subjectivity_detection_udf(\"word\"))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da578c76",
   "metadata": {},
   "source": [
    "#### Run the main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87f56eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export PYSPARK_SUBMIT_ARGS=\"--master local[2] pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6329212f",
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11888/4228684822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# create Spark session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetAppName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MyApp\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetMaster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sentiment analysis using Spark\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "# create Spark session\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(conf=SparkConf().setAppName(\"MyApp\").setMaster(\"local\"))\n",
    "spark = SparkSession.builder.appName(\"Sentiment analysis using Spark\").getOrCreate()\n",
    "\n",
    "# read the tweet data from socket\n",
    "lines = spark.readStream.format(\"socket\").option(\"host\", \"\").option(\"port\", 5555).load()\n",
    "\n",
    "# Preprocess the data\n",
    "words = preprocessing(lines)\n",
    "\n",
    "# text classification to define polarity and subjectivity\n",
    "words = text_classification(words)\n",
    "words = words.repartition(1)\n",
    "\n",
    "query = words.writeStream.queryName(\"all_tweets\")\\\n",
    "    .outputMode(\"append\").format(\"parquet\")\\\n",
    "    .option(\"path\", \"./parc\")\\\n",
    "    .option(\"checkpointLocation\", \"./check\")\\\n",
    "    .trigger(processingTime='60 seconds').start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbcaec7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ea077",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d525003",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
